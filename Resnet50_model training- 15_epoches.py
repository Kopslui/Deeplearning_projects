# -*- coding: utf-8 -*-
"""dl_resnet50.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XKv7hLcOvsRP4wFRMqyCQ17arBpGopKL
"""

from tensorflow.keras import layers, models
from tensorflow.keras.datasets import mnist
import numpy as np

# Load and preprocess MNIST data
(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0

# Print dataset size
print("Dataset Size:")
print("Total number of samples:", len(x_train) + len(x_test))

# Print training data size
print("\nTraining Data Size:")
print("Number of training samples:", len(x_train))

# Print test data size
print("\nTest Data Size:")
print("Number of test samples:", len(x_test))

import matplotlib.pyplot as plt
from tensorflow.keras.datasets import mnist

# Plot sample images from training dataset
plt.figure(figsize=(10, 5))
for i in range(10):  # Plot 10 samples
    plt.subplot(2, 5, i + 1)
    plt.imshow(x_train[i], cmap='gray')
    plt.title(f"Label: {y_train[i]}")
    plt.axis('off')

plt.tight_layout()
plt.show()

# Plot sample images from testing dataset

plt.figure(figsize=(12, 6))
plt.suptitle('Sample Images from Testing Dataset', fontsize=16)
for i in range(10):  # Plot 10 samples
    plt.subplot(2, 5, i + 1)
    plt.imshow(x_test[i], cmap='gray')
    plt.title(f"Label: {y_test[i]}")
    plt.axis('off')

plt.tight_layout()
plt.show()

# Reshape data to fit the network input shape
x_train = np.expand_dims(x_train, axis=-1)
x_test = np.expand_dims(x_test, axis=-1)

# Define ResNet-50 architecture

def residual_block(x, filters, kernel_size=3, strides=1):
  #layer1
    y = layers.Conv2D(filters, kernel_size, strides=strides, padding='same')(x)
    y = layers.BatchNormalization()(y)
    y = layers.ReLU()(y)

#layer2
    y = layers.Conv2D(filters, kernel_size, padding='same')(y)
    y = layers.BatchNormalization()(y)

#layer3
    if strides != 1 or x.shape[-1] != filters:
        x = layers.Conv2D(filters, 1, strides=strides, padding='same')(x)

#shortcut
    return layers.ReLU()(layers.add([x, y]))



def ResNet50(input_shape=(28, 28, 1), num_classes=10):

    inputs = layers.Input(shape=input_shape)
    #stage 1 : conv2D -> batchnormalization -> relu -> maxpool
    x = layers.Conv2D(32, 7, strides=2, padding='same')(inputs)
    x = layers.BatchNormalization()(x)
    x = layers.ReLU()(x)
    x = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(x)
    #layer 1,2,3
    for filters in [64, 128, 256]:
        strides = 1 if filters == 64 else 2
        x = residual_block(x, filters, strides=strides)
        for _ in range(2):
            x = residual_block(x, filters)

    x = layers.GlobalAveragePooling2D()(x)
    x = layers.Dense(128, activation='relu')(x)
    outputs = layers.Dense(num_classes, activation='softmax')(x)

    return models.Model(inputs, outputs)

# Define hyperparameters
alpha = 0.001
beta = 0.99
batch_size = 32
epochs = 15

# Split training data into train/validation
validation_split = 0.1
validation_split_index = int(len(x_train) * validation_split)
x_val, y_val = x_train[:validation_split_index], y_train[:validation_split_index]
x_train, y_train = x_train[validation_split_index:], y_train[validation_split_index:]

# Compile the model
import tensorflow as tf
model = ResNet50()
model.summary()
model.compile(optimizer=tf.keras.optimizers.SGD(lr=alpha, momentum=beta),
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

from keras.utils import plot_model
plot_model(model, show_shapes=True)

# Training loop
for epoch in range(epochs + 1):
    if epoch > 0:
        # Train the model
        history = model.fit(x_train, y_train, batch_size=batch_size, epochs=1, validation_data=(x_val, y_val), verbose=1)

        # Evaluation
        train_loss, train_acc = model.evaluate(x_train, y_train, verbose=0)
        val_loss, val_acc = model.evaluate(x_val, y_val, verbose=0)

        print(f'Epoch {epoch}:')
        print(f'Training Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}')
        print(f'Validation Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}')

for epoch in range(epochs + 1):
    if epoch > 0:
        # Train the model
        history = model.fit(x_train, y_train, batch_size=64, epochs=1,
                            validation_data=(x_val, y_val), verbose=1)

        # Evaluation
        train_loss, train_acc = model.evaluate(x_train, y_train, verbose=0)
        val_loss, val_acc = model.evaluate(x_val, y_val, verbose=0)

        print(f'Epoch {epoch}:')
        print(f'Training Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}')
        print(f'Validation Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}')

# Plot loss and accuracy curves
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training and Validation Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training and Validation Accuracy')
plt.legend()

plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt

# Data
epochs = range(1, 16)
train_loss = [0.0973, 0.0675, 0.0775, 0.0266, 0.0280, 0.0230, 0.0148, 0.0105, 0.0303, 0.0246, 0.0067, 0.0076, 0.0089, 0.0083, 0.0139]
train_accuracy = [0.9741, 0.9813, 0.9780, 0.9922, 0.9915, 0.9930, 0.9958, 0.9969, 0.9904, 0.9926, 0.9981, 0.9976, 0.9972, 0.9975, 0.9961]

# Plot train loss
plt.plot(epochs, train_loss, label='Train Loss')
plt.title('Train Loss per Epoch')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.grid(True)

# Plot train accuracy on secondary y-axis
plt.twinx()
plt.plot(epochs, train_accuracy, 'ro-', label='Train Accuracy')
plt.ylabel('Accuracy')

# Set labels and legend
plt.legend()
plt.show()

import matplotlib.pyplot as plt

# Data
epochs = range(1, 16)
val_loss = [0.1065, 0.0758, 0.0893, 0.0472, 0.0467, 0.0474, 0.0399, 0.0385, 0.0629, 0.0585, 0.0368, 0.0355, 0.0481, 0.0481, 0.0391]
val_accuracy = [0.9738, 0.9802, 0.9787, 0.9868, 0.9857, 0.9882, 0.9880, 0.9910, 0.9852, 0.9878, 0.9913, 0.9913, 0.9885, 0.9912, 0.9897]
# Plot train loss
plt.plot(epochs, val_loss, label='Validation Loss')
plt.title('Validation Loss per Epoch')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.grid(True)

# Plot train accuracy on secondary y-axis
plt.twinx()
plt.plot(epochs, val_accuracy, 'ro-', label='Validation Accuracy')
plt.ylabel('Accuracy')

# Set labels and legend
plt.legend()
plt.show()

model.save("Num_image_classification.h5")

# Make predictions on the test set
predictions = model.predict(x_test)

# Predicted class labels (highest probability class)
predicted_labels = np.argmax(predictions, axis=1)

# Displaying some predictions

for i in range(10):
    print("Predicted:", predicted_labels[i], "Actual:", y_test[i])

import matplotlib.pyplot as plt

# Make predictions on the test set
predictions = model.predict(x_test)

# Predicted class labels (highest probability class)
predicted_labels = np.argmax(predictions, axis=1)

# Displaying some predictions with images
plt.figure(figsize=(10, 10))
for i in range(10):
    plt.subplot(5, 5, i + 1)
    plt.imshow(x_test[i].reshape(28, 28), cmap='gray')
    plt.title(f"Predicted: {predicted_labels[i]}, Actual: {y_test[i]}")
    plt.axis('off')

plt.tight_layout()
plt.show()

import numpy as np
from sklearn.metrics import confusion_matrix
# Make predictions on the test set
predictions = model.predict(x_test)

# Predicted class labels (highest probability class)
predicted_labels = np.argmax(predictions, axis=1)
# Calculate confusion matrix
conf_matrix = confusion_matrix(y_test, predicted_labels)

# Print confusion matrix
print("Confusion Matrix:")
print(conf_matrix)

import cv2
import matplotlib.pyplot as plt

# Load the input image
input_image_path = "/content/eight.png"
input_image = cv2.imread(input_image_path, cv2.IMREAD_GRAYSCALE)

# Resize the image to match the input size expected by the model
resized_image = cv2.resize(input_image, (28, 28))

# Normalize the pixel values to be in the range [0, 1]
normalized_image = resized_image / 255.0

# Reshape the image to match the input shape expected by the model
input_data = normalized_image.reshape(1, 28, 28, 1)

# Use the trained model to predict the number
predictions = model.predict(input_data)

# Get the predicted number (index of the class with highest probability)
predicted_number = predictions.argmax()

# Display the input image along with the predicted value
plt.imshow(resized_image, cmap='gray')
plt.title(f"Predicted Number: {predicted_number}")
plt.axis('off')
plt.show()

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score

# Load the trained model
model = tf.keras.models.load_model('Num_image_classification.h5')

# Evaluate the model on test data
test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)
print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}')

# Get predictions on test data
y_pred = np.argmax(model.predict(x_test), axis=1)

# Calculate confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)

# Plot confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.title('Confusion Matrix')
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.show()

# Calculate and print classification report
print("Classification Report:")
print(classification_report(y_test, y_pred))

# Calculate and print accuracy, precision, recall, and F1-score
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
f1 = f1_score(y_test, y_pred, average='weighted')

print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1-score: {f1:.4f}")

# Total test accuracy
test_loss, test_accuracy = model.evaluate(x_test, y_test)
print(f"Total Test Accuracy: {test_accuracy * 100:.2f}%")

test_loss_values = []
test_accuracy_values = []

# Testing loop
for epoch in range(epochs):
    # Evaluation on test data
    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)
    test_loss_values.append(test_loss)
    test_accuracy_values.append(test_acc)

    print(f'Epoch {epoch + 1}:')
    print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}')

# Plot loss graph for testing data
plt.figure(figsize=(10, 6))
plt.plot(test_loss_values, label='Test Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Test Loss Graph')
plt.legend()
plt.show()

# Plot accuracy graph for testing data
plt.figure(figsize=(10, 6))
plt.plot(test_accuracy_values, label='Test Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Test Accuracy Graph')
plt.legend()
plt.show()